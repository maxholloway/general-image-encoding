{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Image Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gist here is that non-image problems can become image problems if we encode features as pixel channels, and then train an image classifier/regressor on the generated image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Getting Data (handled by user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tabular data; user should ensure that all data is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we have some tabular data (say, in a dataframe). Since this will be automated, we will brute-force create a large number of features that hopefully describe the data better than the raw input. We will do this by using the FeatureSynthesis class in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Clustering Features and Assigning to Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. Ensure that the number of features, $m$, is divisible by the quantity $c\\cdot4^n$ for some $n$, and number of channels per pixel, $c$. If not, go back to the __Feature Engineering__ step and create more features or remove features in order to satisfy this condition.\n",
    "2. Let the data table with the features (in our case, ```pandas.DataFrame```) be called ```features```. Then we convert this to a numpy array, called $X$. The columns represent values for each feature, and each row represents one entry/example. Now note that in traditional cluster analysis, examples are clustered together by minimizing a distance metric, which is computed by finding the examples' different feature lengths. However, in this case, we actually want to group features by example values. Put another way, we want to group the synthetic features that are closest together in value, and the way we determine their similarity is by seeing how similar the values are for their various examples. Hence, in order to cluster the features, we will perform cluster analysis on $X^T$. When there is a large number of examples in $X$, then $X^T$ will have a large number of columns, implying that cluster analysis on $X^T$ will fall victim to the curse of dimensionality. Dimensionality reduction techniques may become helpful to reduce the number of columns (i.e. decrease the number of examples to be used). One option is to perform PCA and get only the most distinct columns of $X^T$. Keep in mind, each feature is represented as a row of $X^T$, so dimensionality reduction on $X^T$ will not decrease the number of generated features.\n",
    "3. Run a function inside the ImageCreation class to create a transformation pipeline. This pipeline will have the following functionality:\n",
    "    * Fit\n",
    "        - Uses ```populate_image_with_feature_names``` on input synthetic features.\n",
    "        - Flattens the feature name array\n",
    "        - (IF fit_and_transform): Re-shuffles the input synthetic features\n",
    "    * Transform\n",
    "        - Takes in a dataframe of only original features, nothing more and nothing less; anything more will be dropped, and if required columns are missing, an exception will be raised.\n",
    "        - Iteratively looks at lowest level features in feature_names_image, perform and store the transformations, then go on to the next higher level of features until there are no more features left. Store all features in a dataframe ```df```.\n",
    "        - Rearrange the columns of ```df``` to fit the order of the columns in the image, and return the DataFrame.    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea for feature selection/dimensionality reduction (in general):\n",
    "    - Transpose of regular feature array ($X$ -> $X^T$)\n",
    "    - K clusters\n",
    "    - See what examples of $X^T$ are in what groups (i.e. what columns of $X$ are most similar)\n",
    "    - Perform some sort of averaging for each group\n",
    "    - Proceed with only K features    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Wrapping into an API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Make Predictions! (handled by user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
