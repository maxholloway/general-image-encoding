{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a document using a simple (greedy) algorithm for balancing clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of helper functions here for the main algo. Most are self-explanatory, but the less intuitive ones have docstrings. This is not the focus of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(cluster_elements):\n",
    "    return cluster_elements.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(clusters_dict):\n",
    "    return {k : get_centroid(clusters_dict[k]) for k in clusters_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_num_elements(group_name, clusters_dict):\n",
    "    return clusters_dict[group_name].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_group_sizes(clusters_dict):\n",
    "    return {group_name : get_group_num_elements(group_name, clusters_dict) for group_name in clusters_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_with_fewest_elements(clusters_dict):\n",
    "    '''\n",
    "    Given a dictionary, mapping from group name\n",
    "    to a numpy array of group element coordinates,\n",
    "    return the name (AKA key) of the group that has\n",
    "    the fewest number of elements. Ties are not handled\n",
    "    arbitrarily.\n",
    "    '''\n",
    "    group_names = list(clusters_dict.keys()) # create indexable list\n",
    "    num_elements_list = [ get_group_num_elements(group_name, clusters_dict) for group_name in group_names ] # find number of elements for each key\n",
    "    index_of_min = np.argmin(num_elements_list) # find index of min for the key\n",
    "    return group_names[index_of_min] # return the key at the index where the min occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_metric(a_coords, b_coords):\n",
    "    '''\n",
    "    This is flexible, but right now it's Euclidean\n",
    "    distance. It could alternatively be absolute distance,\n",
    "    or absolute distance cubed, or whatever.'''\n",
    "    difference_array = a_coords - b_coords\n",
    "    return np.linalg.norm(difference_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances_from_small_group_centroid(cluster_dict, group_names, small_group_centroid, \n",
    "                                            small_group_num_elements):\n",
    "    '''\n",
    "    Goes and looks at all specified groups in a given\n",
    "    cluster dictionary. It reports the distance from\n",
    "    each individual point to the reference element.\n",
    "    \n",
    "    cluster_dict: a mapping from the name of each cluster to a numpy array of element\n",
    "    group_names: iterable of strings representing keys in cluster_dict (like names for the clusters)\n",
    "    small_group_centroid: 1 dimensional numpy array of numbers \n",
    "    small_group_num_elements: the number of elements in the smallest group\n",
    "    return: \n",
    "        dictionary {\n",
    "            distance : dictionary{\n",
    "            'group_name': <string group name>, \n",
    "            'element': <np.array element values>\n",
    "            } \n",
    "        }\n",
    "        \n",
    "    '''\n",
    "    distances_from_small_group_centroid = {} \n",
    "    for group_name in group_names:\n",
    "        group_num_elements = get_group_num_elements(group_name, cluster_dict)\n",
    "        assert (group_num_elements >= small_group_num_elements), 'One of the non-smallest groups has fewer elements than the alleged smallest group. Ensure that the smallest group is being chosen correctly.'\n",
    "\n",
    "        # The rule is that we can only take elements from a cluster that currently\n",
    "        # has at least 2 more elements than the cluster with the least number of elements\n",
    "        if (group_num_elements - small_group_num_elements) >= 2:\n",
    "            group_elements = cluster_dict[group_name]\n",
    "            # This could be sped up with list comprehension, but not implementing at this stage\n",
    "            # so as to preserve clarity\n",
    "            for element in group_elements:\n",
    "                distance_to_small_group_centroid = distance_metric(small_group_centroid, element)\n",
    "                distances_from_small_group_centroid[distance_to_small_group_centroid] = {\n",
    "                    'group_name':group_name, 'element':element\n",
    "                }\n",
    "    return distances_from_small_group_centroid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_clusters(cluster_dict):\n",
    "    '''\n",
    "    The gist of this is to create a\n",
    "    dataframe with columns being\n",
    "    the x, y, and group name, and\n",
    "    then plotting this in seaborn\n",
    "    with the hue being the group name.\n",
    "    '''\n",
    "    def get_total_num_elements(cluster_dict):\n",
    "        '''\n",
    "        Just finds how many elements there\n",
    "        are total in the cluster_dict (not\n",
    "        how many numbers, but how many\n",
    "        elements; an element may have\n",
    "        multiple dimensions)'''\n",
    "        total = 0\n",
    "        for group_name in cluster_dict.keys():\n",
    "            total += get_group_num_elements(group_name, cluster_dict)\n",
    "        return total\n",
    "    \n",
    "    num_elements = get_total_num_elements(cluster_dict)\n",
    "    all_elements = [ [0 for j in range(3)] for i in range(num_elements) ]\n",
    "    row_counter = 0\n",
    "    for group_name in cluster_dict.keys():\n",
    "        cluster = cluster_dict[group_name]\n",
    "        for element in cluster:\n",
    "            all_elements[row_counter] = [group_name] + element.tolist()\n",
    "            row_counter += 1\n",
    "    all_elements_df = pd.DataFrame(all_elements, columns=['group_name', 'x', 'y'])\n",
    "#     print(all_elements_df)\n",
    "    sns.scatterplot(x='x', y='y', hue='group_name', data=all_elements_df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for this make sense, we will generate a random field of data that occupies four quadrants in 2D space. Although this approach should technically generalize to n-dimensional space. Here, we will generate some arbitrary clusters for example. However, these clusters could come from any clustering algorithm; in the original write up, I imagined that they may originate from k-means, but this is very versatile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def make_cluster(approx_centroid, noise_max, num_elements):\n",
    "    '''\n",
    "    Generates a cluster-ish area around the\n",
    "    approx_centroid coordinates.\n",
    "    \n",
    "    Returns an \n",
    "    '''\n",
    "#     assert type(approx_centroid) == type(['is', 'a', 'list'])\n",
    "    cluster = []\n",
    "    for i in range(num_elements):\n",
    "        noise = np.random.uniform(low=-noise_max, high=noise_max, size=len(approx_centroid))\n",
    "        coordinates = np.array(approx_centroid) + noise\n",
    "        cluster += [coordinates]\n",
    "    return np.array(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_centroids = [[0, 0], [10, 0], [0, 10], [10, 10]]\n",
    "clusters = {\n",
    "    'A' : make_cluster([0, 0], 2, 10), # based around (0, 0)\n",
    "    'B' : make_cluster([10, 0], 2, 15), # based around (10, 0)\n",
    "    'C' : make_cluster([0, 10], 2, 8), # based around (0, 10)\n",
    "    'D' : make_cluster([10, 10], 2, 7) # based around (10, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_clusters(cluster_dict_inp, max_iterations=100, verbose='text'):\n",
    "    '''\n",
    "    Description:\n",
    "        This method takes in clusters and then balances all of the clusters so\n",
    "        that they have the same number of elements (or are within one of each other).\n",
    "    \n",
    "    Parameters:\n",
    "        cluster_dict_inp: a dictionary that maps from cluster names to numpy arrays;\n",
    "                            the dimension of the array is the dimension of a sample\n",
    "        max_iterations: the maximum number of iterations before the algorithm stops;\n",
    "                        this is a fail-safe from indefinite looping (although this\n",
    "                        should not be an issue if the code is correct)\n",
    "        verbose: string, specifying the mode of verbosity; if it is 'all', then\n",
    "                 both text and plots will be displayed; if 'plot', then only plots\n",
    "                 will be displayed, not text; if 'text', then only text will be \n",
    "                 displayed, not plots.\n",
    "    Return:\n",
    "        a dictionary of the exact same form as cluster_dict_inp, except with balanced\n",
    "        clusters\n",
    "    '''\n",
    "    cluster_dict = cluster_dict_inp.copy() # copy, so as not to edit original\n",
    "    \n",
    "    counter = 0 \n",
    "    while counter < max_iterations:\n",
    "        # Get centroid of the smallest group\n",
    "        if verbose.lower() in ('text', 'all'): print(f'Group sizes: {get_all_group_sizes(cluster_dict)}')\n",
    "        small_group_name = get_group_with_fewest_elements(cluster_dict)\n",
    "        small_group_num_elements = get_group_num_elements(small_group_name, cluster_dict)\n",
    "        centroids = get_centroids(cluster_dict)\n",
    "        small_group_centroid = centroids[small_group_name]\n",
    "\n",
    "        # Get nearest element that's in a different group with at least \n",
    "        other_group_names = set(cluster_dict.keys())\n",
    "        other_group_names.remove(small_group_name)\n",
    "\n",
    "        # See how far the small group is from \n",
    "        distances_from_small_group_centroid = get_distances_from_small_group_centroid(cluster_dict,\n",
    "                other_group_names, small_group_centroid, small_group_num_elements)\n",
    "        if not distances_from_small_group_centroid:\n",
    "            # If the method returned an empty dictionary of possible distances,\n",
    "            # this implies that there are no further changes to make, and thus the\n",
    "            # function is finished running.\n",
    "            if verbose.lower() in ('text', 'all'): print('There are no more small groups.')\n",
    "            return cluster_dict\n",
    "        else:\n",
    "            # Now find the smallest centroid and move it from its current cluster to the smallest cluster\n",
    "            distances_from_small_group_centroid_list = distances_from_small_group_centroid.keys()\n",
    "            shortest_dist_from_small_centroid = min(distances_from_small_group_centroid_list)\n",
    "            moving_element_information = distances_from_small_group_centroid[shortest_dist_from_small_centroid]\n",
    "            moving_element_previous_group_name = moving_element_information['group_name']\n",
    "            moving_element_previous_cluster = cluster_dict[moving_element_previous_group_name]\n",
    "            moving_element = moving_element_information['element']\n",
    "\n",
    "            # Get the index of the row that should be taken out of the old cluster\n",
    "            index_of_deletion = np.argwhere(cluster_dict[moving_element_previous_group_name]==moving_element)[0, 0]\n",
    "            # Move row out of old cluster\n",
    "            cluster_dict[moving_element_previous_group_name] = np.delete(moving_element_previous_cluster, index_of_deletion, axis=0)\n",
    "            # Move row to new, small cluster\n",
    "            cluster_dict[small_group_name] = np.append( cluster_dict[small_group_name], [moving_element], axis=0 )\n",
    "\n",
    "            if verbose.lower() in ('text', 'all'): print(f'Moving {moving_element} from cluster '\n",
    "                                                         + f'{moving_element_previous_group_name}'\n",
    "                                                          + f' to cluster {small_group_name}')\n",
    "\n",
    "            # Plotting only works for 2 dimensional data. This checks if the data is 2D\n",
    "            is2d = len(cluster_dict[list(cluster_dict.keys())[0]][0]) == 2\n",
    "            if verbose.lower() in ('plot', 'all') and is2d: plot_clusters(cluster_dict)\n",
    "            counter += 1\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group sizes: {'A': 10, 'B': 15, 'C': 8, 'D': 7}\n",
      "Moving [11.73172424  1.97746702] from cluster B to cluster D\n",
      "Group sizes: {'A': 10, 'B': 14, 'C': 8, 'D': 8}\n",
      "Moving [-0.71884931  1.26885987] from cluster A to cluster C\n",
      "Group sizes: {'A': 9, 'B': 14, 'C': 9, 'D': 8}\n",
      "Moving [9.88412339 1.77237694] from cluster B to cluster D\n",
      "Group sizes: {'A': 9, 'B': 13, 'C': 9, 'D': 9}\n",
      "Moving [9.13842474 0.30012904] from cluster B to cluster A\n",
      "Group sizes: {'A': 10, 'B': 12, 'C': 9, 'D': 9}\n",
      "Moving [9.16027345 0.57506863] from cluster B to cluster C\n",
      "Group sizes: {'A': 10, 'B': 11, 'C': 10, 'D': 9}\n",
      "Moving [10.46424925  1.54655366] from cluster B to cluster D\n",
      "Group sizes: {'A': 10, 'B': 10, 'C': 10, 'D': 10}\n",
      "There are no more small groups.\n"
     ]
    }
   ],
   "source": [
    "balanced_clusters = balance_clusters(clusters, verbose='text')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
